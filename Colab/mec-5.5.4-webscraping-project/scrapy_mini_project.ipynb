{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapy Mini Project/Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Scrapy\n",
    "# !pip install Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will walk you through these tasks:\n",
    "\n",
    "1. Creating a new Scrapy project\n",
    "2. Writing a spider to crawl a site and extract data\n",
    "3. Exporting the scraped data using the command line\n",
    "4. Changing spider to recursively follow links\n",
    "5. Using spider arguments\n",
    "6. Load the scraped data into a SQLlite3 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !scrapy startproject scrapy_mini_project #only do this first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./scrapy_mini_project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-28 02:12:44 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapy_mini_project)\n",
      "2021-01-28 02:12:44 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.9 | packaged by conda-forge | (default, Dec  9 2020, 21:08:20) - [GCC 9.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-72-generic-x86_64-with-debian-stretch-sid\n",
      "2021-01-28 02:12:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2021-01-28 02:12:44 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'scrapy_mini_project',\n",
      " 'NEWSPIDER_MODULE': 'scrapy_mini_project.spiders',\n",
      " 'ROBOTSTXT_OBEY': True,\n",
      " 'SPIDER_MODULES': ['scrapy_mini_project.spiders']}\n",
      "2021-01-28 02:12:44 [scrapy.extensions.telnet] INFO: Telnet Password: 6052527b2f6739a3\n",
      "2021-01-28 02:12:44 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2021-01-28 02:12:44 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2021-01-28 02:12:44 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2021-01-28 02:12:44 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2021-01-28 02:12:44 [scrapy.core.engine] INFO: Spider opened\n",
      "2021-01-28 02:12:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2021-01-28 02:12:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2021-01-28 02:12:44 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)\n",
      "2021-01-28 02:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)\n",
      "2021-01-28 02:12:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/2/> (referer: None)\n",
      "2021-01-28 02:12:45 [quotes] DEBUG: Saved file quotes-1.html\n",
      "2021-01-28 02:12:45 [quotes] DEBUG: Saved file quotes-2.html\n",
      "2021-01-28 02:12:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2021-01-28 02:12:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 693,\n",
      " 'downloader/request_count': 3,\n",
      " 'downloader/request_method_count/GET': 3,\n",
      " 'downloader/response_bytes': 5657,\n",
      " 'downloader/response_count': 3,\n",
      " 'downloader/response_status_count/200': 2,\n",
      " 'downloader/response_status_count/404': 1,\n",
      " 'elapsed_time_seconds': 0.33798,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2021, 1, 28, 2, 12, 45, 102062),\n",
      " 'log_count/DEBUG': 5,\n",
      " 'log_count/INFO': 10,\n",
      " 'memusage/max': 56307712,\n",
      " 'memusage/startup': 56307712,\n",
      " 'response_received_count': 3,\n",
      " 'robotstxt/request_count': 1,\n",
      " 'robotstxt/response_count': 1,\n",
      " 'robotstxt/response_status_count/404': 1,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'start_time': datetime.datetime(2021, 1, 28, 2, 12, 44, 764082)}\n",
      "2021-01-28 02:12:45 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Text Using CSS and Xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-28 03:43:50 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapy_mini_project)\n",
      "2021-01-28 03:43:50 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.9 | packaged by conda-forge | (default, Dec  9 2020, 21:08:20) - [GCC 9.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-72-generic-x86_64-with-debian-stretch-sid\n",
      "2021-01-28 03:43:50 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2021-01-28 03:43:50 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'scrapy_mini_project',\n",
      " 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',\n",
      " 'LOGSTATS_INTERVAL': 0,\n",
      " 'NEWSPIDER_MODULE': 'scrapy_mini_project.spiders',\n",
      " 'ROBOTSTXT_OBEY': True,\n",
      " 'SPIDER_MODULES': ['scrapy_mini_project.spiders']}\n",
      "2021-01-28 03:43:50 [scrapy.extensions.telnet] INFO: Telnet Password: 22f34dce7bd2314a\n",
      "2021-01-28 03:43:50 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage']\n",
      "2021-01-28 03:43:50 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2021-01-28 03:43:50 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2021-01-28 03:43:50 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2021-01-28 03:43:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025\n",
      "2021-01-28 03:43:50 [scrapy.core.engine] INFO: Spider opened\n",
      "2021-01-28 03:43:50 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)\n",
      "2021-01-28 03:43:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)\n",
      "2021-01-28 03:43:51 [asyncio] DEBUG: Using selector: EpollSelector\n",
      "[s] Available Scrapy objects:\n",
      "[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)\n",
      "[s]   crawler    <scrapy.crawler.Crawler object at 0x7fc95f791790>\n",
      "[s]   item       {}\n",
      "[s]   request    <GET http://quotes.toscrape.com/page/1/>\n",
      "[s]   response   <200 http://quotes.toscrape.com/page/1/>\n",
      "[s]   settings   <scrapy.settings.Settings object at 0x7fc95f78ded0>\n",
      "[s]   spider     <DefaultSpider 'default' at 0x7fc95fbff510>\n",
      "[s] Useful shortcuts:\n",
      "[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)\n",
      "[s]   fetch(req)                  Fetch a scrapy.Request and update local objects \n",
      "[s]   shelp()           Shell help (print this help)\n",
      "[s]   view(response)    View response in a browser\n",
      "2021-01-28 03:43:51 [asyncio] DEBUG: Using selector: EpollSelector\n",
      "\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;28mIn [\u001b[0;92;1m1\u001b[0;38;5;28m]: \u001b[0m                                                                       \u001b[8D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
      "\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h0m\u001b[J\u001b[0;38;5;28mIn [\u001b[0;92;1m1\u001b[0;38;5;28m]: \u001b[0m                                                                       "
     ]
    }
   ],
   "source": [
    "!scrapy shell 'http://quotes.toscrape.com/page/1/' #need to  run this in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !response.css('title::text').getall() #need to  run this in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !response.css('title').getall() #need to  run this in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !response.css('title::text').re(r'Quotes.*') #need to  run this in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !response.xpath('//title') #need to  run this in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !response.xpath('//title/text()').get() #need to  run this in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do this inorder to run in Jupyter (otherwise run this in shell to get response object: scrapy shell 'http://quotes.toscrape.com/page/1/' )\n",
    "\n",
    "import requests\n",
    "import scrapy\n",
    "\n",
    "res = requests.get('http://quotes.toscrape.com/page/1/')\n",
    "response = scrapy.http.TextResponse(res.url, body=res.text, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.css(\"div.quote\").getall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting quotes and authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}\n",
      "{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}\n",
      "{'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein', 'tags': ['inspirational', 'life', 'live', 'miracle', 'miracles']}\n",
      "{'text': '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'author': 'Jane Austen', 'tags': ['aliteracy', 'books', 'classic', 'humor']}\n",
      "{'text': \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", 'author': 'Marilyn Monroe', 'tags': ['be-yourself', 'inspirational']}\n",
      "{'text': '“Try not to become a man of success. Rather become a man of value.”', 'author': 'Albert Einstein', 'tags': ['adulthood', 'success', 'value']}\n",
      "{'text': '“It is better to be hated for what you are than to be loved for what you are not.”', 'author': 'André Gide', 'tags': ['life', 'love']}\n",
      "{'text': \"“I have not failed. I've just found 10,000 ways that won't work.”\", 'author': 'Thomas A. Edison', 'tags': ['edison', 'failure', 'inspirational', 'paraphrased']}\n",
      "{'text': \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", 'author': 'Eleanor Roosevelt', 'tags': ['misattributed-eleanor-roosevelt']}\n",
      "{'text': '“A day without sunshine is like, you know, night.”', 'author': 'Steve Martin', 'tags': ['humor', 'obvious', 'simile']}\n"
     ]
    }
   ],
   "source": [
    "for quote in response.css(\"div.quote\"):\n",
    "    text = quote.css(\"span.text::text\").get()\n",
    "    author = quote.css(\"small.author::text\").get()\n",
    "    tags = quote.css(\"div.tags a.tag::text\").getall()\n",
    "    print(dict(text=text, author=author, tags=tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Data Using Spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./scrapy_mini_project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-28 06:06:21 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapy_mini_project)\n",
      "2021-01-28 06:06:21 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.9 | packaged by conda-forge | (default, Dec  9 2020, 21:08:20) - [GCC 9.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-72-generic-x86_64-with-debian-stretch-sid\n",
      "2021-01-28 06:06:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2021-01-28 06:06:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'scrapy_mini_project',\n",
      " 'NEWSPIDER_MODULE': 'scrapy_mini_project.spiders',\n",
      " 'ROBOTSTXT_OBEY': True,\n",
      " 'SPIDER_MODULES': ['scrapy_mini_project.spiders']}\n",
      "2021-01-28 06:06:21 [scrapy.extensions.telnet] INFO: Telnet Password: 06f7290fa47719f5\n",
      "2021-01-28 06:06:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2021-01-28 06:06:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2021-01-28 06:06:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2021-01-28 06:06:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2021-01-28 06:06:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2021-01-28 06:06:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2021-01-28 06:06:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025\n",
      "2021-01-28 06:06:21 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)\n",
      "2021-01-28 06:06:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)\n",
      "2021-01-28 06:06:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/2/> (referer: None)\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "{'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein', 'tags': ['inspirational', 'life', 'live', 'miracle', 'miracles']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "{'text': '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'author': 'Jane Austen', 'tags': ['aliteracy', 'books', 'classic', 'humor']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "{'text': \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", 'author': 'Marilyn Monroe', 'tags': ['be-yourself', 'inspirational']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "{'text': '“Try not to become a man of success. Rather become a man of value.”', 'author': 'Albert Einstein', 'tags': ['adulthood', 'success', 'value']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "{'text': '“It is better to be hated for what you are than to be loved for what you are not.”', 'author': 'André Gide', 'tags': ['life', 'love']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "{'text': \"“I have not failed. I've just found 10,000 ways that won't work.”\", 'author': 'Thomas A. Edison', 'tags': ['edison', 'failure', 'inspirational', 'paraphrased']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "{'text': \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", 'author': 'Eleanor Roosevelt', 'tags': ['misattributed-eleanor-roosevelt']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/1/>\n",
      "{'text': '“A day without sunshine is like, you know, night.”', 'author': 'Steve Martin', 'tags': ['humor', 'obvious', 'simile']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "{'text': \"“This life is what you make it. No matter what, you're going to mess up sometimes, it's a universal truth. But the good part is you get to decide how you're going to mess it up. Girls will be your friends - they'll act like it anyway. But just remember, some come, some go. The ones that stay with you through everything - they're your true best friends. Don't let go of them. Also remember, sisters make the best friends in the world. As for lovers, well, they'll come and go too. And baby, I hate to say it, most of them - actually pretty much all of them are going to break your heart, but you can't give up because if you give up, you'll never find your soulmate. You'll never find that half who makes you whole and that goes for everything. Just because you fail once, doesn't mean you're gonna fail at everything. Keep trying, hold on, and always, always, always believe in yourself, because if you don't, then who will, sweetie? So keep your head high, keep your chin up, and most importantly, keep smiling, because life's a beautiful thing and there's so much to smile about.”\", 'author': 'Marilyn Monroe', 'tags': ['friends', 'heartbreak', 'inspirational', 'life', 'love', 'sisters']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "{'text': '“It takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends.”', 'author': 'J.K. Rowling', 'tags': ['courage', 'friends']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "{'text': \"“If you can't explain it to a six year old, you don't understand it yourself.”\", 'author': 'Albert Einstein', 'tags': ['simplicity', 'understand']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "{'text': \"“You may not be her first, her last, or her only. She loved before she may love again. But if she loves you now, what else matters? She's not perfect—you aren't either, and the two of you may never be perfect together but if she can make you laugh, cause you to think twice, and admit to being human and making mistakes, hold onto her and give her the most you can. She may not be thinking about you every second of the day, but she will give you a part of her that she knows you can break—her heart. So don't hurt her, don't change her, don't analyze and don't expect more than she can give. Smile when she makes you happy, let her know when she makes you mad, and miss her when she's not there.”\", 'author': 'Bob Marley', 'tags': ['love']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "{'text': '“I like nonsense, it wakes up the brain cells. Fantasy is a necessary ingredient in living.”', 'author': 'Dr. Seuss', 'tags': ['fantasy']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "{'text': '“I may not have gone where I intended to go, but I think I have ended up where I needed to be.”', 'author': 'Douglas Adams', 'tags': ['life', 'navigation']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "{'text': \"“The opposite of love is not hate, it's indifference. The opposite of art is not ugliness, it's indifference. The opposite of faith is not heresy, it's indifference. And the opposite of life is not death, it's indifference.”\", 'author': 'Elie Wiesel', 'tags': ['activism', 'apathy', 'hate', 'indifference', 'inspirational', 'love', 'opposite', 'philosophy']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "{'text': '“It is not a lack of love, but a lack of friendship that makes unhappy marriages.”', 'author': 'Friedrich Nietzsche', 'tags': ['friendship', 'lack-of-friendship', 'lack-of-love', 'love', 'marriage', 'unhappy-marriage']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "{'text': '“Good friends, good books, and a sleepy conscience: this is the ideal life.”', 'author': 'Mark Twain', 'tags': ['books', 'contentment', 'friends', 'friendship', 'life']}\n",
      "2021-01-28 06:06:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/2/>\n",
      "{'text': '“Life is what happens to us while we are making other plans.”', 'author': 'Allen Saunders', 'tags': ['fate', 'life', 'misattributed-john-lennon', 'planning', 'plans']}\n",
      "2021-01-28 06:06:22 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2021-01-28 06:06:22 [scrapy.extensions.feedexport] INFO: Stored json feed (20 items) in: quotes_extract.json\n",
      "2021-01-28 06:06:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 693,\n",
      " 'downloader/request_count': 3,\n",
      " 'downloader/request_method_count/GET': 3,\n",
      " 'downloader/response_bytes': 5642,\n",
      " 'downloader/response_count': 3,\n",
      " 'downloader/response_status_count/200': 2,\n",
      " 'downloader/response_status_count/404': 1,\n",
      " 'elapsed_time_seconds': 0.353039,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2021, 1, 28, 6, 6, 22, 97929),\n",
      " 'item_scraped_count': 20,\n",
      " 'log_count/DEBUG': 23,\n",
      " 'log_count/INFO': 11,\n",
      " 'memusage/max': 56750080,\n",
      " 'memusage/startup': 56750080,\n",
      " 'response_received_count': 3,\n",
      " 'robotstxt/request_count': 1,\n",
      " 'robotstxt/response_count': 1,\n",
      " 'robotstxt/response_status_count/404': 1,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'start_time': datetime.datetime(2021, 1, 28, 6, 6, 21, 744890)}\n",
      "2021-01-28 06:06:22 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "# !scrapy crawl quotes_extract\n",
    "!scrapy crawl quotes_extract -o 'quotes_extract.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl quotes_extract_rec_to_scrap_css -o css-scraper-results.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save extracted json data into SQLlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/mec-5.5.4-webscraping-project/scrapy_mini_project\n"
     ]
    }
   ],
   "source": [
    "os.chdir('./scrapy_mini_project')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = r\"./pythonsqlite.db\"\n",
    "\n",
    "# create a database connection\n",
    "conn = sqlite3.connect(database) # creates a new db (if it doesn't exist)\n",
    "\n",
    "#create a cursor object\n",
    "curr = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sqlite3 ./pythonsqlite.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fd9377f0a40>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a quotes table\n",
    "sql_create_quotes_table = \"\"\" CREATE TABLE IF NOT EXISTS quotes (\n",
    "                                    id integer PRIMARY KEY,\n",
    "                                    Description text NOT NULL,\n",
    "                                    Author text NOT NULL,\n",
    "                                    Tags text\n",
    "                                ); \"\"\"\n",
    "    \n",
    "curr.execute(sql_create_quotes_table) #to create a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #insert data into the quote table (playground)\n",
    "# sql_insert_data_quotes = \"\"\" INSERT INTO quotes(id, Description, Author, Tags) \n",
    "#                             VALUES (1,'description 1','author 1','tag 1')\"\"\"\n",
    "# curr = conn.cursor()\n",
    "# curr.execute(sql_insert_data_quotes)\n",
    "# conn.commit() #to make our changes persistent in the database.\n",
    "# last_rowid = curr.lastrowid #get the number of rows affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #query the database\n",
    "# curr.execute('select * from quotes') #to run a query\n",
    "# results = curr.fetchall() #to get qury results\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fd936b79180>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# curr.execute('drop table quotes;') #to delete table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #To delete entries from table\n",
    "# for i in range(100):\n",
    "#     sql_delete_query = \"\"\"DELETE from quotes where id = %d\"\"\" %i\n",
    "#     curr.execute(sql_delete_query)\n",
    "#     conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def copy_data_from_json_to_db():\n",
    "    #copy data from *.json into the database\n",
    "    with open('css-scraper-results.json','r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    sql_base_cmnd = \"INSERT INTO quotes(id, Description, Author, Tags) VALUES\"\n",
    "    for idx, d in enumerate(data):\n",
    "        description = d['text'].replace('\\'', '')\n",
    "        author = d['author'].replace('\\'', '')\n",
    "        tags = ' '.join(d['tags'])\n",
    "\n",
    "        sql_cmnd = f\"{sql_base_cmnd}({idx}, '{description[1:-1]}', '{author}', '{tags}')\"\n",
    "        #sql_cmnd = f\"{sql_base_cmnd}({idx}, {description[1:-1]}, {author}, {tags})\" #doesn't work\n",
    "        #print(sql_cmnd)\n",
    "        curr.execute(sql_cmnd)\n",
    "        conn.commit() #to make our changes persistent in the database.\n",
    "\n",
    "    last_rowid = curr.lastrowid #get the number of rows affected\n",
    "    return last_word\n",
    "\n",
    "# copy_data_from_json_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_rowid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr.execute('select * from quotes') #to run a query\n",
    "results = curr.fetchall() #to get qury results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
