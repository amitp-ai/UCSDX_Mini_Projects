# Mini-Projects That I Completed

### Basic Info:
* Most of the mini-projects are done on paperspace (using my Github account) and three on Databricks (for Spark/SQL related ones)
* For paperspace projects, log into my paperspace account (using my Github account)
* For Spark projects
	download project from: 
	(https://drive.google.com/drive/folders/1VoweKytaQW_rnoro5EyalsC3w6WTDvPp) 
	and copy into Databricks: 
	(https://community.cloud.databricks.com/?o=7526501889408240)

---

### Project Info:

1. **mec-3.4.1-use-apis-to-retrieve-data (API)**  
	"It’s time to hone your APIs skills by working on a mini-project"

2. **mec-5.3.10-data-wrangling-with-pandas (Pandas)**  
	"In this data wrangling mini-project, you’ll practice transformation and visualization techniques using pandas. Knowing how to use these techniques will be especially helpful if you work at a company that keeps the majority of their data in relational databases and flat files. This mini-project has been adopted from the Brandon Rhodes tutorial that you completed earlier in the subunit and will focus on movie data from IMDB."

3. **mec-5.4.4-json-based-data-exercise (Pandas)**  
	"This World Bank dataset from a school quality improvement project in Ethiopia is a good example of a real-life dataset that you’re likely to encounter as an AI/ML engineer. Sharpen your data wrangling skills by completing your mini-project so that you can then apply what you’ve learned to your capstone, which will occur later on in the course."

4. **mec-5.5.4-web-scraping (Web Scraping)**  
	"In this mini-project, you'll create your own dataset through web-scraping. As you'll see first hand, the datasets that you collect through web scraping are typically messy and unruly, and will require a lot of wrangling before you can run them through a model."

5. **sql_with_spark_5-6-6 (PySpark/SQL)**  
	"For this project, you will use Databricks and work through a series of exercises using Spark SQL. The purpose of this project is to help you familiarize yourself with the Spark SQL interface, which scales easily, making it great for working with huge datasets. However, because we don’t want you to have to worry about changing your SQL queries, the dataset you will be working with is not very large."

6. **data_wrangling_at_scale_with_spark_6-4-1 (PySpark)**  
	"For this project, you will continue using Databricks and work with real-world datasets from NASA HTTP logs. The purpose of this project is to become familiar with both structured and unstructured data, analyze large-scale data with Spark, practice more advanced wrangling and cleaning techniques, and try your hand at data transformation."

	This is a good project on Explore-Transform-Load (ETL) pipeline at scale using Pyspark. In particular, a large dataset containing over 3 million records of web server logs is downloaded (i.e. extracted/sourced) from NASA's website. Each record is a raw string that is transformed into 7 distinct columns/fields using Regular Expressions. The dataset is further transformed by dropping/imputing null values. Exploratory data analysis (EDA) is then performed on the transformed dataset. Finally, the transformed dataset is saved (i.e. loaded) in the Databricks filestore system in two different formats, csv and json, for future use. 

7. **Linear Regression mini-project_11-4-1**
	"This is project on linear regression. It also delves into generating statistically significant models."

8. **Logistic Regression mini-project_12-4-2**
	"This is project on classification using logistic regression."

9. **Tree Based Algorithms mini-project_13-5-1**
	"This is project on tree based algorithms such as decision tress, random forests, and gradient boosting. Boosting is an ensemble learning technique where weak learners train the subsequent generation of learners to be stronger. This is a sequential learning process that is relatively time and resource intensive, but produces extremely useful results. Some of the highest performing boosting models are XGBoost, GBMlight, and CatBoost."

10. **Clustering mini-project_16-2-6**
	"This is a project on various clustering algorithms such a K-means, affinity propagation, DBSCAN, etc. Different techniques for selecting the number of clusters such as Elbow, Silhoutte, and Gap statistic methods are also analyzed."

11. **Anomaly Detection mini-project_16-4-1**
	"This is a project on anomaly detection for univariate and multivariate datasets. Various methods such a basic statistical analysis, random forest, clustering based local outlier factor (CBLOF), and autoencoders are studied."

12. **Recommendation Systems mini-project_17-4-1**
	"In this project we will use the IMDb and Netflix movie datasets to generate a movie recommender system using a global recommendation system, a content based recommendation system, a collaborative filtering system, and a deep learning based hybrid recommender system."	

13. **Time Series Analysis mini_project_18-5-1**
	"In this project we predict IBM's stock price using traditional statistical models such as ARIMA as well as using deep learning based models such as LSTM."
